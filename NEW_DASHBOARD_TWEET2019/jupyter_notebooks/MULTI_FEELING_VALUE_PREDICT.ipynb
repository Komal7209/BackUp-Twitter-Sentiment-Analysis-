{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Bidirectional,LSTM,Dropout,Dense,Embedding\n",
    "#IMPORT THE REGULARIZERS\n",
    "from tensorflow.keras import regularizers\n",
    "#MULTI TARGET PREDICTION LIBRARIRES CHAINED OUTPUT REGRESSION DUE TO THE DEPENDENCE\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "df=pd.read_csv(\"G:/hell.csv\")\n",
    "df2=pd.read_csv(\"G:/hell2.csv\")\n",
    "\n",
    "\n",
    "df2=df2[df2[\"lang\"]==\"en\"]\n",
    "print(df2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Fortunate to feel calm and relaxed but worried...\n",
      "1                 Not being able to cuddle my family sucks!\n",
      "2         Spending time at home with the family and work...\n",
      "3         I'm OK, I'm feeling positive, but also a littl...\n",
      "4         Getting very anxious about this whole situatio...\n",
      "                                ...                        \n",
      "475250    The only thing surprising about  #covid19 and ...\n",
      "475253    The Majik of Mind Control and How The Whole Wo...\n",
      "475254    @HillaryClinton @WHO Hillary!. Perhaps you sho...\n",
      "475256    Whether it is #Brexit or #Covid19 exceptionali...\n",
      "475258    It’s been a long day. I’ve been taking my temp...\n",
      "Length: 269571, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.columns[0], axis=1,inplace=True)\n",
    "dt=pd.concat([df[\"text_short\"],df[\"text_long\"],df2[\"text\"]],axis=0)\n",
    "print(dt)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42519\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]][6 6 6 ... 7 7 7]\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]][7 4 6 ... 1 5 2]\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(oov_token='OOV')\n",
    "tokenizer.fit_on_texts(dt)\n",
    "total_words=len(tokenizer.word_index)+1\n",
    "\n",
    "input_long=[]\n",
    "max_len_feed=0\n",
    "for i in df[\"text_short\"]:\n",
    "    input_long.append(tokenizer.texts_to_sequences([i])[0])\n",
    "for i in df[\"text_long\"]:\n",
    "    if(len(i)>max_len_feed):\n",
    "        max_len_feed=len(i)\n",
    "    input_long.append(tokenizer.texts_to_sequences([i])[0])\n",
    "\n",
    "\n",
    "input_long=np.array(pad_sequences(input_long,maxlen=int(0.45*max_len_feed),padding='pre'))\n",
    "#PREPARE THE MULTIPLE OUTPUT COLUMNS TO BE PREDICTED\n",
    "print(len(input_long))\n",
    "#BELOW CODE FOR CATEGORICAL TRANSFORMATION FOR OUTPUT\n",
    "import tensorflow.keras.utils as ku\n",
    "uniques_worry,ids_worry=np.unique(np.array(df[\"worry\"]),return_inverse=True)\n",
    "output_worry=ku.to_categorical(ids_worry,len(uniques_worry))\n",
    "\n",
    "uniques_anger,ids_anger=np.unique(np.array(df[\"anger\"]),return_inverse=True)\n",
    "output_anger=ku.to_categorical(ids_anger,len(uniques_anger))\n",
    "\n",
    "uniques_fear,ids_fear=np.unique(np.array(df[\"fear\"]),return_inverse=True)\n",
    "output_fear=ku.to_categorical(ids_fear,len(uniques_fear))\n",
    "\n",
    "uniques_disgust,ids_disgust=np.unique(np.array(df[\"disgust\"]),return_inverse=True)\n",
    "output_disgust=ku.to_categorical(ids_disgust,len(uniques_disgust))\n",
    "\n",
    "uniques_anxiety,ids_anxiety=np.unique(np.array(df[\"anxiety\"]),return_inverse=True)\n",
    "output_anxiety=ku.to_categorical(ids_anxiety,len(uniques_anxiety))\n",
    "\n",
    "uniques_sadness,ids_sadness=np.unique(np.array(df[\"sadness\"]),return_inverse=True)\n",
    "output_sadness=ku.to_categorical(ids_sadness,len(uniques_sadness))\n",
    "\n",
    "uniques_happiness,ids_happiness=np.unique(np.array(df[\"happiness\"]),return_inverse=True)\n",
    "output_happiness=ku.to_categorical(ids_happiness,len(uniques_happiness))\n",
    "\n",
    "uniques_relaxation,ids_relaxation=np.unique(np.array(df[\"relaxation\"]),return_inverse=True)\n",
    "output_relaxation=ku.to_categorical(ids_relaxation,len(uniques_relaxation))\n",
    "\n",
    "uniques_desire,ids_desire=np.unique(np.array(df[\"desire\"]),return_inverse=True)\n",
    "output_desire=ku.to_categorical(ids_desire,len(uniques_desire))\n",
    "print(str(output_worry)+str(np.array(df[\"worry\"])))\n",
    "print(str(output_relaxation)+str(np.array(df[\"relaxation\"])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "#from tensorflow.keras.lay\n",
    "#CREATE THE BIDIRECTIONAL LSTM MODEL \n",
    "#SERIALZIED THE MODEL USING LSTM AND BIDRIECTIONAL LSTM\n",
    "inputss=keras.Input(shape=(None,),name=\"multi_feeling\",dtype=\"int32\")\n",
    "#TAKING THE INPUT ABOVE HERE\n",
    "x=keras.layers.Embedding(total_words, 70, input_length=int(0.45*max_len_feed))(inputss)\n",
    "x=Bidirectional(LSTM(90, return_sequences = True))(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=LSTM(70)(x)\n",
    "x=Dense(total_words/4, activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "\n",
    "worry=Dense(9,activation='softmax')(x)\n",
    "anger=Dense(9,activation='softmax')(x)\n",
    "disgust=Dense(9,activation='softmax')(x)\n",
    "fear=Dense(9,activation='softmax')(x)\n",
    "anxiety=Dense(9,activation='softmax')(x)\n",
    "sadness=Dense(9,activation='softmax')(x)\n",
    "happiness=Dense(9,activation='softmax')(x)\n",
    "relaxation=Dense(9,activation='softmax')(x)\n",
    "desire=Dense(9,activation='softmax')(x)\n",
    "model=keras.Model(inputss,[worry,anger,disgust,fear,anxiety,\n",
    "                                        sadness,happiness,relaxation,desire])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"length max\")\n",
    "print(int(0.65*max_len_feed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#CHAIN FED MULTI OUPPUT REGRESSION MODEL\n",
    "#Wrapper=RegressorChain(model)\n",
    "history = model.fit(input_long,[output_worry,output_anger,output_disgust,output_fear,output_anxiety,\n",
    "output_sadness,output_happiness,output_relaxation,output_desire],validation_split=0.28, epochs=25, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"G:/multi_traget_feeling_precise2_NEWMAINTF.hdf5\",include_optimizer=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PLOT THE ACCURACY AND LOSS GRAPH\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}